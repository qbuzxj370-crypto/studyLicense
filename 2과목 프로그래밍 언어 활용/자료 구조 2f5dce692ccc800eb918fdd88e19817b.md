# 자료 구조

# 자료구조

## 자료구조의 정의

### 자료구조(Data Structure)의 개념

효율적인 프로그램을 작성할 때 최우선 고려 사항이 바로 저장 공간의 효율성과 실행 시간의 신속성

자료구조는 프로그램에서 사용할 데이터를 기억장치(메모리/저장장치)에 효과적으로 저장하기 위한 **표현 방식**과, 그 데이터들 사이의 **관계(구조)** 및 데이터를 처리하기 위한 **연산 방법**을 함께 정의한 개념

- 자료의 표현(저장 방식)과 관련된 연산(검색/삽입/삭제 등)의 집합
- 일련의 자료들을 목적에 맞게 조직화•구조화하여 연산을 효율적으로 수행
- 대부분의 자료구조는 다양한 연산을 수행할 수 있으나, 연산별 시간/공간 효율이 서로 다름
- 선택한 자료구조에 따라 시간복잡도·공간복잡도 및 실제 실행 성능(캐시 효율 등)이 달라져 프로그램 성능에 큰 영향을 미친다.

## 선형 자료구조

### 배열 (Array)

동일한 자료형의 데이터들을 연속된(인접한) 기억장치 공간에 같은 크기 단위로 저장하여, 첨자(인덱스)를 통해 순서대로 접근할 수 있는 선형 자료구조

- 일반적으로 정적 자료구조로 취급되어 생성 시 크기가 결정되며, 크기 변경(확장/축소)이 어렵다.
- 중간 삽입/삭제는 이후 원소들을 이동해야 하므로 시간복잡도는 O(n)
    
    (끝에서의 삽입/삭제는 상황에 따라 O(1) 가능)
    
- 삭제 시에도 실제로 원소를 당겨 채우지 않거나(논리적 삭제) “빈 값”을 남기는 방식으로 처리하면, 배열 내부에 사용하지 않는 공간이 생겨 메모리 낭비 발생 가능
- 연속 메모리에 저장되므로 **인덱스를 이용한 임의 접근(Random Access)**이 가능하며, 접근 시간은 O(1)
- 데이터가 연속적으로 배치되어 캐시 효율이 좋아 반복 처리(순회)에 유리한 자료 구조
- 데이터마다 동일한 이름의 변수를 사용하여 처리가 간편
- 사용한 첨자의 개수에 따라 1차원, 2차원, …, n차원 배열이라고 부른다.

### 선형 리스트 (Linear List)

자료들이 일정한 순서에 의해 나열된 자료 구조

- 배열을 이용하는 연속 리스트(순차 리스트)와 포인터를 이용하는 연결 리스트로 구분

**연속 리스트 (Contiguous List, Sequential List)**

- 배열과 같이 연속되는 **기억장치 공간**에 데이터를 저장하는 자료 구조
- 기억장소를 연속적으로 배정받기 때문에 기억장소 이용 효율은 밀도가 1로서 가장 좋다.
- 임의 접근(인덱스 접근)이 가능하여 접근 시간이 빠르다. (**O(1)**)
- 중간에 데이터를 삽입하기 위해서는 연속된 빈 공간이 있어야 하며 삽입•삭제 시 자료의 이동이 필요

**연결 리스트 (Linked List)**

- 데이터(노드)를 반드시 연속적으로 배열시키지 않고 임의의 저장공간에 기억시키되 자료 항목의 순서에 따라 노드의 포인터 부분을 이용하여 서로 연결시킨 자료 구조
- 노드의 삽입•삭제 작업이 용이
- 기억 공간이 연속적으로 놓여 있지 않아도 저장 가능하며, 필요할 때마다 노드를 할당할 수 있어 크기 변경이 유연
- 각 노드에 연결을 위한 링크(포인터) 필드가 필요하므로 연속 리스트에 비해 메모리 오버헤드가 발생하고 공간 이용 효율이 낮을 수 있음
- 인덱스를 통한 임의 접근이 어려워 연결을 위한 포인터를 찾는 시간이 필요하기 때문에 접근 속도가 느리다.
- 링크(포인터)가 손상되거나 중간 노드가 유실지면 그 다음 노드를 찾기 어렵다

### 스택 (Stack)

리스트의 한쪽 끝으로만 자료의 삽입(push), 삭제(pop) 작업이 이루어지는 자료 구조

- 가장 나중에 삽입된 자료가 가장 먼저 삭제되는 후입선출(LIFO, Last In First Out)방식으로 자료를 처리
- 기본 연산: push(삽입), pop(삭제), peek/top(맨 위 원소 확인)
- **스택의 용도**: 재귀 호출, 후위(Postfix) 표기법, 서브루틴 호출, 인터럽트 처리, 깊이 우선 탐색 등과 같이 이전 상태로 되돌아가는 작업에 사용
- 스택의 모든 공간이 채워져 있는 상태에서 데이터 삽입 시 **오버플로**(Overflow)가 발생하며 더 이상 삭제할 데이터가 없는 상태에서 데이터 삭제 시 **언더플로**(Underflow)가 발생
- **TOP** : 현재 스택의 가장 위(마지막으로 삽입된 데이터)의 위치를 가리키는 변수/포인터(또는 인덱스)
- **Bottom** : 스택의 가장 아래(가장 처음에 저장된 데이터)의 위치

### 큐 (Queue)

자료의 삽입(enqueue)은 한쪽 끝(Rear)에서만, 삭제(dequeue)는 반대쪽 끝(Front)에서만 이루어지도록 구성한 선형 자료구조

- 가장 먼저 삽입된 자료가 가장 먼저 삭제되는 선입선출(FIFO, First In First Out)방식으로 자료를 처리\
- 기본 연산: enqueue(삽입), dequeue(삭제), peek/front(맨 앞 원소 확인)
- 큐의 상태를 관리하기 위해 보통 Front, Rear 두 개의 포인터/인덱스를 사용
- **프론트(F, Front) 포인터(또는 인덱스)**
    - 가장 먼저 삽입된 자료의 기억 공간을 가리키는 포인터
    - 삭제 작업 시 사용
- **리어(R, Rear) 포인터(또는 인덱스)**
    - 가장 마지막에 삽입된 자료의 기억 공간을 가리키는 포인터
    - 삽입 작업 시 사용
- 큐의 용도 : 운영체제 작업 스케줄링, 프로세스/스레드 대기열, 프린터 스풀링, 네트워크 패킷 처리, BFS 등
- 배열로 구현한 순차 큐는 삭제가 반복되면 앞쪽 공간이 비어도 재사용이 어려워 가짜 오버플로가 발생할 수 있으며, 이를 해결하기 위해 원형 큐(Circular Queue)를 사용

### 데크 (Deque)

데이터의 삽입과 삭제가 리스트의 양쪽 끝(Front/Rear)에서 모두 가능한 자료 구조

- Double Ended Queue의 약자
- Stack과 Queue의 장점만 따서 그 연산을 일반화한 구조로, 상황에 따라 스택/큐처럼 사용 가능
- 기본 연산
    - 삽입: addFirst(앞 삽입), addLast(뒤 삽입)
    - 삭제: removeFirst(앞 삭제), removeLast(뒤 삭제)
- **제한형 데크(Restricted Deque)** 종류 존재
    - **입력 제한 데크 (Input-Restricted Deque)**: 삽입은 한쪽 끝에서만 가능, 삭제는 양쪽에서 가능 (Scrol)
    - **출력 제한 데크 (Output-Restricted Deque)**: 삭제는 한쪽 끝에서만 가능, 삽입은 양쪽에서 가능 (Shelf)

## 비선형 자료구조

### 그래프 (Graph)

그래프 G는 정점 V(Vertex)와 간선 E(Edge)의 두 집합으로 구성되며, 일반적으로 $G=(V,E)$로 표현

- 간선의 방향성 유무에 따라 방향 그래프와 무방향 그래프로 구분
- 통신망(Network) 교통망, 이항관계, 연립방정식, 유기화학 구조식, 무향선분 해법 등에 응용
- 트리는 사이클이 없는 연결된 무방향 그래프 중에서 사이클이 없는 그래프

**방향 그래프 (Directed Graph)**

n개의 정점으로 구성된 방향 그래프에서 최대 간선 수는 $n(n-1)$

**무방향 그래프 (Undirected Graph)**

n개의 정점으로 구성된 무방향 그래프에서 최대 간선 수는 $n(n-1)/2$

### **인접 행렬(Adjacency Matrix)을 이용한 그래프의 표현 방법**

- 그래프의 정점 집합이 $V=\{V_1, V_2, \dots, V_n\}$일 때, $n \times n$행렬 $P$를 사용하여 간선 정보를 저장
- 행렬의 원소 $P_{ij}$는 정점 $V_i$에서 $V_j$로의 간선 존재 여부를 나타냄
    
    (가중치 그래프라면 0/1 대신 가중치 값을 저장하고, 간선이 없으면 $\infty$ 또는 0 등으로 표시)
    

**방향 그래프**

- $V_i \rightarrow V_j$ 방향 간선이 있으면 $P_{ij}=1$, 없으면 $P_{ij}=0$
- 일반적으로 $P_{ij} \neq P_{ji}$일 수 있어 대칭이 아닐 수 있음(비대칭)
- 자기 자신으로 가는 간선(루프)이 없으면 $P_{ii}=0$
    
    ![image.png](image%202.png)
    
    |  | 1 | 2 | 3 | 4 | 5 |
    | --- | --- | --- | --- | --- | --- |
    | 1 | 0 | 1 | 0 | 0 | 0 |
    | 2 | 0 | 0 | 1 | 0 | 0 |
    | 3 | 0 | 0 | 0 | 1 | 0 |
    | 4 | 0 | 0 | 0 | 0 | 1 |
    | 5 | 0 | 0 | 1 | 0 | 0 |

**무방향 그래프**

- $V_i$와 $V_j$가 인접(간선 존재)하면 $P_{ij}=1$, 인접하지 않으면 $P_{ij}=0$
- 무방향이므로 $P_{ij}=P_{ji}$가 성립하여 대칭 행렬이 됨
- 루프가 없으면 $P_{ii}=0$
    
    ![image.png](image%203.png)
    
    |  | 1 | 2 | 3 | 4 |
    | --- | --- | --- | --- | --- |
    | 1 | 0 | 1 | 1 | 1 |
    | 2 | 1 | 0 | 1 | 1 |
    | 3 | 1 | 1 | 0 | 1 |
    | 4 | 1 | 1 | 1 | 0 |

**특징(성능)**

- 공간복잡도: $O(V^2)$
- 간선 존재 여부 확인: $O(1)$
- 한 정점의 인접 정점들을 찾기: $O(V)$
- 밀집 그래프(Dense Graph)에서 유리하며, 정점 수가 큰 희소 그래프(Sparse Graph)에서는 메모리 낭비가 크다

### 트리

**트리의 개요**

트리는 정점(Node, 노드)과 선분(Branch, 가지)을 이용하여 사이클을 이루지 않도록 구성한 그래프(Graph)의 특수한 형태

- 트리는 하나의 기억 공간을 노드라고 하며 노드와 노드를 연결하는 선을 링크(Link)라고 한다.
- 트리는 가족의 계보(족보), 조직도 등을 표현하기에 적합

**트리의 운행법 (Traversal)**

트리를 구성하는 각 노드들을 찾아가는 방법

- 이진 트리를 운행하는 방법은 산술식의 표기법과 연관성을 갖는다.
- **이진 트리의 운행법**
    - **Preorder 운행** : Root → Left → Right 순
    - **Inorder 운행** : Left → Root → Right 순
    - **Postorder 운행** : Left → Right → Root 순

### 수식 표기법

산술식을 표현·계산하기 위해 **이진 표현식 트리(Expression Tree)**를 사용할 수 있으며, 트리의 운행법(Traversal)에 따라 표기법이 결정

**전위 / 중위 / 후위 표기법**

이진 트리로 만들어진 수식을 운행하면 트리의 운행법에 따라 표기법 구분

A + B * C

- **전위 표기법 (Prefix)** : 연산자**(**Root) → Left → Right 순 + A * B C
- **중위 표기법 (InFix)** : Left → 연산자**(**Root) → Right 순 A + B * C
- **후위 표기법 (PostFix)** : Left → Right → 연산자**(**Root) 순 A B C * +

**표기법 변경**

- 중위 표기법은 괄호와 연산자 우선순위가 필요하지만, 전위/후위 표기법은 괄호 없이도 계산 순서가 결정됨
- 표기법 변환 및 계산은 주로 **스택(Stack)**을 이용하여 수행함
    
    (예: 중위 → 후위 변환, 후위/전위 수식 계산)
    
- 중위 → 후위
    - 피연산자(숫자/변수)는 즉시 출력
    - ( 는 스택에 push
    - ) 는 스택에서 ( 가 나올 때까지 pop하여 출력, ( 는 제거
    - 연산자 op를 만나면
        - 스택 top이 (가 아니고 연산자일 때,
            - top의 우선순위가 op보다 높으면 pop하여 출력
            - 우선순위가 같으면
                - op가 좌결합(left-assoc)이면 pop하여 출력
                - op가 우결합(right-assoc, 예: ^)이면 pop하지 않음
        - 그 다음 op를 스택에 push
    - 입력이 끝나면 스택에 남은 연산자를 모두 pop하여 출력
- 중위 → 전위
    - 중위식을 reverse(좌우 반전) 한다
    - 괄호를 서로 바꾼다: ( ↔ )
    - 변환된 식을 중위 → 후위 규칙으로 후위식으로 만든다
    - 결과 후위식을 reverse 하면 전위식이 된다
- 후위 → 중위 (Stack)
    - 왼쪽부터 오른쪽으로 토큰을 읽는다.
    - 피연산자(숫자/변수)면 스택에 push
    - 연산자 op면:
        - 스택에서 b를 pop, 그 다음 a를 pop
        - 문자열 (a op b)를 만들어 push
    - 입력이 끝나면 스택에 남은 1개가 중위식
- 전위 → 중위 (Stack)
    - 오른쪽부터 왼쪽으로 토큰을 읽는다.
    - 피연산자면 스택에 push
    - 연산자 `op`면:
        - 스택에서 a를 pop, 그 다음 b를 pop
        - 문자열 `(a op b)`를 만들어 push
    - 입력이 끝나면 스택에 남은 1개가 중위식

# 정렬과 검색

## 정렬 알고리즘

### 삽입 정렬 (Insertion Sort)

가장 간단한 정렬 방식으로 이미 정렬된(혹은 거의 정렬된) 구간에 새 원소 1개를 알맞은 위치에 삽입하며 정렬

- 왼쪽 부분 배열을 항상 정렬된 상태로 유지하면서, 다음 원소를 그 안에 끼워 넣음
    - $i=1$부터 시작해 $A[i]$를 $A[0..i-1]$에 삽입 → $i$가 끝나면 전체 정렬
- 동작(회전 개념)
    - 2번째 키를 1번째 키와 비교해 적절히 배치(1회전)
    - 3번째 키를 앞의 (1~2번째)와 비교해 적절히 배치(2회전)
    - …
    - n번째 키를 앞의 (1~n-1번째)와 비교하여 적절히 삽입
- 특징
    - 안정 정렬(Stable): 같은 값의 상대 순서가 유지됨(일반 구현에서 `>` 비교를 사용할 때)
    - 제자리 정렬(In-place): 추가 메모리 사용이 거의 없다.
    - 부분적으로 정렬된 입력에 매우 유리
- 시간 복잡도
    - 최선(이미 정렬) : $O(n)$
- 평균/최악 : $O(n^2)$

![image.png](image%204.png)

### 쉘 정렬 (Shell Sort)

삽입 정렬을 확장한 개념으로 간격(gap, $h$)을 두고 멀리 떨어진 원소들을 먼저 정돈한 뒤 gap을 줄여가며 마무리하는 정렬

- **간격 기반 정렬**
    - 입력 파일을 간격 $h$로 나눈 서브 파일(부분수열) 들을 만들고(보통 $h=\sqrt[3]{n}$)
    - 각 서브 파일을 삽입 정렬 방식으로 정렬하는 과정을 반복
    - $h$를 점점 줄여 최종적으로 $h=1$에서 일반 삽입 정렬로 마무리
- 동작 방식(정의)
    - $h$-정렬: 모든 $k$에 대해 인덱스가 $k, k+h, k+2h, ...$인 부분수열이 정렬된 상태
    - 이를 여러 $h$에 대해 수행하면, 마지막 $h=1$ 삽입 정렬이 매우 쉬워져 전체 성능이 향상
- 특징
    - 입력 파일이 부분적으로 정렬되어 있는 경우 특히 유리
    - 제자리 정렬(In-place)
    - 일반적으로 안정 정렬이 아니다.(Not stable) (gap 이동 과정에서 같은 값의 상대 순서가 바뀔 수 있음)
- 간격($h$) 선택
    - 성능이 gap 수열에 크게 의존
    - 예시: $h = \lfloor n/2 \rfloor, \lfloor n/4 \rfloor, \dots, 1$ (구현은 쉬우나 최악 $O(n^2)$ 가능)
- 시간 복잡도
    - 평균 성능은 gap 수열에 따라 달라지며, 많은 경우 삽입 정렬보다 훨씬 빠르다.
    - 일부 수열에서 평균이 대략 $O(n^{1.5})$로 알려져 있으나, 일반적으로 하나의 식으로 단정하기 어렵고
    - 최악의 경우 $O(n^2)$가 될 수 있다.(특히 단순한 gap 수열에서)

![image.png](image%205.png)

![image.png](image%206.png)

### 선택 정렬 (Selection Sort)

n개의 레코드 중에서 최소값을 찾아 첫 번째 레코드 위치에 두고 나머지$(n-1)$개 중에서 다시 최소값을 찾아 두 번째 레코드 위치로 보내는 방식을 반복하여 정렬하는 방식

- **최소값 선택**
    - 1회전: 전체에서 최소값을 찾아 1번째 위치로 이동
    - 2회전: 2번째 원소부터 끝까지 중 최소값을 찾아 2번째 위치로 이동
    - …
    - $(n-1)$회전까지 반복하면 정렬 완료
- 특징
    - 매 회전마다 최소값을 “선택”하여 제자리에 둠 → 최소값 선택
    - 제자리 정렬(In-place): 추가 메모리 사용이 거의 없다.
    - 비교 횟수는 입력 상태(정렬 정도)와 무관하게 거의 동일
    - 일반 구현은 안정 정렬이 아니다.(Not stable) (최소값과의 교환 과정에서 같은 값의 상대 순서가 바뀔 수 있음)
- 시간 복잡도
    - 최선/평균/최악 : $O(n^2)$
    - (비교 횟수) $(n-1) + (n-2) + \cdots + 1 = {n(n-1)}/{2}$
- 이동(교환) 횟수
    - 각 회전당 최대 1회 교환 → 최대 $(n-1)$회 교환 (비교에 비해 이동은 적은 편)

![image.png](image%207.png)

### 버블 정렬 (Bubble Sort)

주어진 파일에서 인접한 두 개의 레코드 키 값을 비교하여 그 크기에 따라 레코드 위치를 서로 교환하는 과정을 반복하여 정렬하는 방식

- **인접 요소 교환**
    - 1회전: (1,2), (2,3), …, (n-1,n) 인접 쌍을 비교/교환 → 가장 큰 값이 맨 뒤로 “버블처럼” 이동
    - 2회전: 맨 뒤를 제외한 구간에서 반복
    - … 반복하여 전체 정렬
- 계속 정렬할지 여부를 플래그 비트($f$)로 결정
    - 한 회전 동안 교환이 한 번도 없으면 이미 정렬된 상태이므로 $f$를 통해 조기 종료 가능
    - (일반적 구현) swapped=false로 시작 → 스왑 발생 시 true → 끝까지 false면 종료
- 특징
    - 인접 요소 교환 기반 정렬
    - 일반적으로 안정 정렬(Stable) (같은 값은 교환하지 않도록 구현할 때)
    - 제자리 정렬(In-place): 추가 메모리 거의 없음

시간 복잡도

- 최선(이미 정렬 + 플래그 조기 종료) : $O(n)$
- 평균/최악 : $O(n^2)$
- (비교 횟수) 대략 ${n(n-1)}/2$수준

![image.png](image%208.png)

### 퀵 정렬 (Quick Sort)

레코드의 많은 자료 이동을 없애고 하나의 파일을 부분적으로 나누어 가면서 정렬하는 방법으로 하나의 기준값(Pivot)을 중심으로 배열을 분할하고, 각 부분 배열에 대해 동일한 과정을 재귀적으로 적용하여 정렬하는 알고리즘

- 기준값(피벗)을 기준으로 작은 값은 왼쪽 부분 배열, 큰 값은 오른쪽 부분 배열로 분할
- 분할된 부분 배열에 대해 재귀적으로 정렬 수행
- 위치에 관계없이 임의의 원소를 피벗으로 선택 가능
- 내부 정렬(in-place sort) 방식으로 추가적인 메모리 사용이 적음
- 재귀 호출(되부름)을 사용하므로 스택(Stack) 공간이 필요
- 분할 정복(Divide and Conquer) 전략을 사용하는 대표적인 정렬 알고리즘
- **분할 정복 방식**
    - **분할 (Divide)**
        
        기준값인 피봇(Pivot)을 중심으로 정렬할 자료들을 2개의 부분집합으로 분할
        
    - **정복 (Conquer)** : 부분집합의 원소들 중 피봇보다 작은 원소들은 왼쪽, 피봇보다 큰 원소들은 오른쪽 부분집합으로 정렬하는 과정을 재귀적으로 수행
    - 부분집합의 크기가 더 이상 나누어질 수 없을 때까지 분할과 정복을 반복 수행
- 시간 복잡도
    - 평균 : $O(nlog_2n)$
    - 최악 : $O(n^2)$
        - 최악의 경우는 이미 정렬된 배열에서 항상 최소값 또는 최대값을 피벗으로 선택하는 경우 발생

![image.png](image%209.png)

### 힙 정렬 (Heap Sort)

전이진 트리(Complete Binary Tree) 기반의 힙(Heap) 구조를 이용한 정렬 방식

- **힙 구조 활용**
    - 입력 데이터를 힙(Heap Tree) 으로 만들고(힙 구성),
    - 힙의 루트(최대/최소 원소)를 꺼내 배열 끝으로 보내는 과정을 반복하여 정렬
- 동작 방식(최대 힙/최소 힙)
    - 최대 힙(Max-Heap) 사용
        - 목적: 오름차순 정렬
        1. 배열을 최대 힙으로 변환(힙 구성)
        2. 루트(최댓값) ↔ 배열의 마지막 원소 교환
        3. 힙 크기를 1 줄인 뒤, 루트에 대해 heapify(Down-Heap) 수행
        4. (2)~(3) 반복 → 큰 값부터 뒤에 고정되며 최종적으로 오름차순 완성
    - 최소 힙(Min-Heap) 사용
        - 목적: 내림차순 정렬
        1. 배열을 최소 힙으로 변환(힙 구성)
        2. 루트(최솟값) ↔ 배열의 마지막 원소 교환
        3. 힙 크기를 1 줄인 뒤, 루트에 대해 heapify(Down-Heap) 수행
        4. (2)~(3) 반복 → 작은 값부터 뒤에 고정되며 최종적으로 내림차순 완성
        - (참고) 오름차순을 최소 힙으로 하려면 루트를 꺼낼 때마다 앞에서부터 채우는 별도 배열을 쓰는 방식이 흔함(이 경우 in-place 성질이 약해짐)
- 특징
    - 힙 구조 활용
    - 제자리 정렬(In-place): 추가 메모리 사용이 적다.(배열 내부에서 수행)
    - 일반적으로 안정 정렬이 아니다.(Not stable) (교환 과정에서 동일 키의 상대 순서가 바뀔 수 있다.)
- 구성된 전이진 트리를 Heap Tree로 변환하여 정렬
- 시간 복잡도
    - 힙 구성 $O(n)$
    - 원소  $n$개 추출 (각각 heapify $O(\log n)$): $O(n \log_2 n)$)
    - 평균/최악 : $O(nlog_2n)$

![image.png](image%2010.png)

### 2-Way 합병 정렬 (Merge Sort)

이미 정렬되어 있는 두 개의 파일(서브리스트)을 한 개의 파일로 합병하는 과정을 반복하여 전체를 정렬하는 방식

- 동작 방식
    - 두 개의 키들을 한 쌍으로 하여 각 쌍에 대한 순서를 정한다.
    - 순서데로 정렬된 각 쌍의 키들을 합병하여 하나의 정렬된 서브리스트를 만든다.
    - 위 과정에서 만들어진 정렬된 서브리스트들을 다시 두 개씩 합병하며, 서브리스트의 크기를 2배씩 늘려 하나의 정렬된 파일이 될 때까지 반복
- 특징
    - 안정 정렬(Stable): 같은 키일 때 왼쪽(앞) 서브리스트 원소를 먼저 선택하면 상대 순서가 유지됨
    - 분할 정복(Divide & Conquer) 기반 정렬(분할 후 합병으로 정렬 완성)
    - 비교 횟수가 입력 상태에 크게 영향받지 않음: 거의 정렬/역순이어도 전체 시간은 비슷한 편
    - 일반적인 배열 구현은 추가 공간 필요 : 합병을 위한 보조 배열이 필요하여 공간 복잡도는 보통 $O(n)$
    - 연결 리스트로 구현하면 합병이 효율적(포인터 조작), 배열은 복사 비용이 발생 가능
- 시간 복잡도
    - 평균/최악 : $O(nlog_2n)$
    
    ![image.png](image%2011.png)
    

### 기수 정렬 (Radix Sort)

Queue를 이용하여 자릿수(Digit)별로 정렬하는 방식

- **자릿수 기반 정렬**
    - 레코드의 키 값을 분석하여 같은 수 또는 문자끼리 그 순서에 맞는 버킷에 분배하였다가 버킷의 순서대로 레코드를 꺼내 정렬에 순서대로 분배하였다가, 버킷의 순서대로 레코드를 꺼내어 정렬하는 과정을 자릿수만큼 반복하여 정렬
- 특징
    - 보통 LSD 방식(Least Significant Digit, 낮은 자릿수부터) 을 많이 사용하며, 이때 각 단계가 안정 정렬(Stable) 이면 전체도 안정 정렬이 됨
    - 키 길이(자릿수)가 고정이거나 범위가 제한적일 때 유리
    - 비교 정렬(퀵/힙/병합)처럼 비교 연산에 의존하지 않는다.
- 시간 복잡도
    - 평균/최악 : **$O(d(n + k))$**
        - $d$ : 자릿수(또는 문자열 길이)
        - $k$ : 각 자릿수의 값 범위(예: 10진수면 10, ASCII면 256)
    - (자주 쓰는 표현) $k$가 상수(예: 10)이고 $d$가 작거나 고정이면 **$O(dn) ≈ O(n)$** 로 본다

![image.png](image%2012.png)

## 검색 기법

### 이분 검색 (이진 검색, Binary Search)

전체 파일을 두 개의 서브 파일로 분리해 가면서 Key 레코드를 검색하는 방식

- 반드시 순서화(정렬)된 파일에서만 검색 가능
- 찾고자 하는 Key  값을 파일의 가운데 레코드 Key값과 비교하면서 검색
- 비교 횟수를 거듭할 때마다 검색 대상이 되는 데이터의 수가 절반으로 감소하므로 탐색 효율이 좋고 탐색 시간이 적게 소요
- 중간 레코드 번호
    - 기본 : $M=(F+L)/2$
    - 오버플로우 방지 권장사항 : $M=F+(L-F)/2$
    - 단 $F$ : 첫 번째 레코드 번호, $L$ : 마지막 레코드 번호
- 시간 복잡도
    - 평균/최악: $O(\log_2 n)$
    - 최선(첫 비교에서 성공): $O(1)$
- 주의점(함정)
    - 정렬이 안 되어 있으면 이분 검색은 성립하지 않는다.
    - 반복 조건을 $F <= L$로 두고 갱신을 $L = M - 1$ 또는 $F = M + 1$로 정확히 해야 무한 루프 회귀 예방

### 해싱 (Hashing)

해시 테이블(Hash Table)이라는 기억공간을 할당하고 해시 함수(Hash Function)를 이용하여 레코드 키에 대한 해시 테이블 내의 홈 주소(Hash Address)를 계산한 후 주어진 레코드를 해당 기억장소에 저장하거나 검색 작업을 수행하는 방식

키를 해시 함수로 숫자 인덱스로 바꿔 해시 테이블의 홈 주소에 저장/조회하는 방식

- 구성 요소
    - 해시 테이블: 키-값(레코드)을 저장하는 배열 기반 기억공간
    - 해시 함수: 키 → 홈 주소(인덱스)로 변환하는 함수
    - 홈 주소(Hash Address): 저장/검색의 기준이 되는 테이블 위치
- 특징
    - 평균적으로 탐색/삽입/삭제가 빠름: $O(1)$ (충돌이 적고 적절히 관리될 때)
    - 키의 비교 정렬 없이도 직접 위치를 계산해 접근 가능
    - 충돌(Collision) 발생 가능: 서로 다른 키가 같은 홈 주소로 매핑될 수 있음
    - 충돌 해결이 핵심
        - 체이닝(Chaining): 같은 홈 주소에 리스트(버킷)로 연결
        - 오픈 어드레싱(Open Addressing): 빈 칸을 찾아 테이블 내부에 저장(선형/이차/이중 해싱 등)
- 시간 복잡도
    - 평균: $O(1)$
    - 최악: $O(n)$ (충돌이 심하면 한 버킷/탐색 경로가 길어질 수 있음)

**필드 해싱**

- 키를 몇 개의 필드(부분 블록) 로 나눈 뒤, 각 필드를 정수로 해석하여 더하거나/가중합/모듈러 등을 적용해 해시 주소를 만드는 방식

**해시 테이블 (Hash Table)**

레코드를 한 개 이상 보관할 수 있는 버킷들로 구성된 기억 공간 

보조기억장치나 주기억장치 모두에 구성 가능

- **버킷 (Bucket)**
    - 하나의 홈 주소를 갖는 파일의 한 구역(단위)을 의미
    - 버킷의 크기는 같은 주소에 동시에 저장 가능한 레코드 수(= 슬롯 수)
- **슬롯 (Slot)**
    - 한 개의 레코드를 저장할 수 있는 공간
    - n개의 슬롯이 모여 하나의 버킷을 형성
- **충돌 현상 (Collison)**
    - 서로 다른 두 개 이상의 레코드가 같은 홈 주소를 갖는 현상
    - $h(k_1)=h(k_2),\,k_1≠k_2$
- **Synonym**
    - 충돌로 인해 같은 Home Address를 갖는 레코드들의 집합
- **Overflow**
    - 계산된 Home Address의 버킷 내에 저장할 기억공간(빈 슬롯)이 없는 상태
    - Bucket을 구성하는 Slot이 여러 개면 Collison은 발생해도 Overflow는 발생하지 않을 수도 있다.

**해싱 함수 (Hashing Function)**

- **제산법 (Division)**
    - 레코드 키($K$)를 해시 테이블의 크기보다 큰 수 중에서 가장 작은 소수(Prime, Q)로 나눈 나머지를 홈 주소로 삼는 방식
    - $∴ h(K)=K\bmod Q$
- **제곱법 (Mid-Square)**
    - 레코드 키 값($K$)을 제곱한 후 그 결과의 중간 비트/중간 자리를 뽑아 홈 주소로 사용하는 방식
    - 키의 하위 자리만 반복되는 패턴(예: 끝자리가 비슷함)을 어느 정도 완화하는 데 도움
- **폴딩법 (Folding)**
    - 레코드 키 값($K$)을 여러 부분(필드)으로 나눈 후 각 부분의 값을 더하거나 XOR(배타적 논리합)한 값을 홈 주소로 삼는 방식
    - 긴 숫자/문자열 키를 다룰 때 자주 설명되며, 필드 해싱과 연결되는 개념
- **기수 변환법 (Redix)**
    - 키 숫자의 진수를 다른 진수로 변환시켜 주소 범위를 넘는 높은 자릿수를 절단하고,
    - 남은 값을 주소 범위에 맞게 **조정**하는 방식
    - (핵심은 키를 “다른 표현”으로 바꿔 분포를 개선하려는 시도)
- **대수적 코딩법 (Algebraic Coding)**
    - 키를 비트열로 보고 각 자리(비트/블록)를 다항식의 계수처럼 취급
    - 이 다항식을 해시표의 크기에 의해 정의된 다항식으로 나누어 얻은 나머지 다항식의 계수를 홈 주소로 삼는 방식
- **숫자 분석법 (Digit Analysis, 계수 분석법)**
    - 키 값을 이루는 숫자의 분포를 분석하여 비교적 고른 자리를 필요한 만큼 택해서 홈 주소로 삼는 방식
- **무작위법 (Random)**
    - 난수를 발생시켜 나온 값을 홈 주소로 삼는 방식

## 데이터 저장소의 개요

### 데이터 저장소

소프트웨어 개발 과정에서 다루어야 할 데이터들을 논리적인 구조로 조직화하거나 물리적인 공간에 구축한 것을 의미

- 논리 데이터 저장소와 물리 데이터 저장소로 구분
- 논리 데이터 저장소 : 데이터 및 데이터 간의 연관성, 제약 조건을 식별하여 논리적인 구조로 조직화한 것
- 물리 데이터 저장소 : 논리 데이터 저장소에 저장된 데이터와 구조들을 소프트웨어가 운용될 물리적 특성을 고려하여 하드웨어적인 저장장치에 저장한 것
- 논리 데이터 저장소를 거쳐 물리적 데이터 저장소를 구축하는 과정은 데이터베이스 구축 과정과 동일